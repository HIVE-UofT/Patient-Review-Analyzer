{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Patient Review Theme Categorization\n",
    "\n",
    "This notebook demonstrates advanced theme categorization using multiple LLM APIs, LangChain, and various prompt engineering techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai groq pandas tqdm langchain python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import Dict, Any, List\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI, ChatGroq\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY_THEMES = [\n",
    "    \"general comment\", \"laboratory\", \"discharge\",\n",
    "    \"parking/transport\", \"infection prevention & control\", \"emergency\",\n",
    "    \"medication/prescription\", \"access/coord of care\", \"unknown\",\n",
    "    \"social services\", \"respect to patient\", \"admit/registration\",\n",
    "    \"nurse/nurse aide\", \"continuity/transition\", \"icu/ccu\", \"religion\",\n",
    "    \"housekeeping/room\", \"families/friends\", \"emotional support\",\n",
    "    \"physical comfort\", \"information/education\", \"billing/accounting\",\n",
    "    \"cardiology\", \"dietary/service\", \"radiology\", \"positive recognition\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThemeResponse(BaseModel):\n",
    "    themes: List[Dict[str, str]] = Field(description=\"List of identified themes with descriptions\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=ThemeResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "OPENAI_API_KEY = \"\"\n",
    "GROQ_API_KEY = \"\"\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_templates():\n",
    "    system_template = \"\"\"You are an expert healthcare analyst specializing in patient experience analysis. \n",
    "    Your task is to analyze patient reviews and identify key themes from the following list: {themes}\n",
    "    \n",
    "    Guidelines:\n",
    "    1. Multiple themes may be present in a single review\n",
    "    2. If no theme matches, use 'unknown'\n",
    "    3. Provide a brief description for each identified theme\n",
    "    4. Consider both explicit and implicit mentions of themes\n",
    "    5. Focus on patient experience and satisfaction aspects\n",
    "    \n",
    "    {format_instructions}\"\"\"\n",
    "    \n",
    "    human_template = \"\"\"Analyze this patient review and identify relevant themes:\n",
    "    \n",
    "    {review}\"\"\"\n",
    "    \n",
    "    system_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "    human_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "    \n",
    "    return ChatPromptTemplate.from_messages([system_prompt, human_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_llm_chains():\n",
    "    prompt_template = create_prompt_templates()\n",
    "    \n",
    "    openai_llm = ChatOpenAI(\n",
    "        temperature=0.7,\n",
    "        model_name=\"gpt-3.5-turbo\",\n",
    "        openai_api_key=OPENAI_API_KEY\n",
    "    )\n",
    "    \n",
    "    groq_llm = ChatGroq(\n",
    "        temperature=0.7,\n",
    "        model_name=\"llama-3.1-70b-versatile\",\n",
    "        groq_api_key=GROQ_API_KEY\n",
    "    )\n",
    "    \n",
    "    openai_chain = LLMChain(\n",
    "        llm=openai_llm,\n",
    "        prompt=prompt_template,\n",
    "        output_parser=parser\n",
    "    )\n",
    "    \n",
    "    groq_chain = LLMChain(\n",
    "        llm=groq_llm,\n",
    "        prompt=prompt_template,\n",
    "        output_parser=parser\n",
    "    )\n",
    "    \n",
    "    return openai_chain, groq_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reviews(file_path: str, limit: int = None) -> List[str]:\n",
    "    df = pd.read_csv(file_path)\n",
    "    if 'review_text' not in df.columns:\n",
    "        raise ValueError(\"CSV file must contain a 'review_text' column\")\n",
    "    reviews = df['review_text'].tolist()\n",
    "    return reviews[:limit] if limit else reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_reviews(reviews: List[str], chain: LLMChain) -> List[Dict[str, Any]]:\n",
    "    results = []\n",
    "    for review in tqdm(reviews, desc=\"Processing reviews\"):\n",
    "        try:\n",
    "            result = chain.run(\n",
    "                review=review,\n",
    "                themes=\", \".join(KEY_THEMES),\n",
    "                format_instructions=parser.get_format_instructions()\n",
    "            )\n",
    "            results.append(result.dict())\n",
    "            time.sleep(1)  \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing review: {e}\")\n",
    "            results.append({\"themes\": []})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_results(openai_results: List[Dict[str, Any]], groq_results: List[Dict[str, Any]], reviews: List[str]):\n",
    "    print(\"\\nDetailed Analysis:\")\n",
    "    for i, (review, openai_result, groq_result) in enumerate(zip(reviews, openai_results, groq_results)):\n",
    "        print(f\"\\nReview {i+1}:\")\n",
    "        print(f\"Text: {review}\")\n",
    "        print(\"\\nOpenAI Analysis:\")\n",
    "        for theme in openai_result['themes']:\n",
    "            print(f\"- {theme['theme']}: {theme['description']}\")\n",
    "        print(\"\\nGroq Analysis:\")\n",
    "        for theme in groq_result['themes']:\n",
    "            print(f\"- {theme['theme']}: {theme['description']}\")\n",
    "        print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_theme_statistics(results: List[Dict[str, Any]], model_name: str):\n",
    "    theme_counts = {}\n",
    "    theme_descriptions = {}\n",
    "    \n",
    "    for result in results:\n",
    "        for theme in result['themes']:\n",
    "            theme_name = theme['theme']\n",
    "            theme_counts[theme_name] = theme_counts.get(theme_name, 0) + 1\n",
    "            if theme_name not in theme_descriptions:\n",
    "                theme_descriptions[theme_name] = set()\n",
    "            theme_descriptions[theme_name].add(theme['description'])\n",
    "    \n",
    "    print(f\"\\nTheme Statistics ({model_name}):\")\n",
    "    for theme, count in sorted(theme_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"\\n{theme} (Count: {count}):\")\n",
    "        print(\"Sample Descriptions:\")\n",
    "        for desc in list(theme_descriptions[theme])[:3]:\n",
    "            print(f\"- {desc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    openai_chain, groq_chain = initialize_llm_chains()\n",
    "    \n",
    "    reviews = load_reviews(\"patient_reviews.csv\", limit=5)\n",
    "    print(f\"Loaded {len(reviews)} reviews\")\n",
    "    \n",
    "    print(\"\\nProcessing with OpenAI...\")\n",
    "    openai_results = process_reviews(reviews, openai_chain)\n",
    "    \n",
    "    print(\"\\nProcessing with Groq...\")\n",
    "    groq_results = process_reviews(reviews, groq_chain)\n",
    "    \n",
    "    analyze_results(openai_results, groq_results, reviews)\n",
    "    \n",
    "    calculate_theme_statistics(openai_results, \"OpenAI\")\n",
    "    calculate_theme_statistics(groq_results, \"Groq\")\n",
    "    \n",
    "    results_df = pd.DataFrame({\n",
    "        'review': reviews,\n",
    "        'openai_themes': [json.dumps(result['themes']) for result in openai_results],\n",
    "        'groq_themes': [json.dumps(result['themes']) for result in groq_results]\n",
    "    })\n",
    "    \n",
    "    results_df.to_csv('theme_categorization_results.csv', index=False)\n",
    "    print(\"\\nResults saved to 'theme_categorization_results.csv'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
